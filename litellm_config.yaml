model_list:
  # Azure deployment for gpt-4.1
  - model_name: gpt-4.1
    litellm_params:
      model: azure/gpt-4.1
      api_base: os.environ/AZURE_OPENAI_ENDPOINT
      api_key: os.environ/AZURE_OPENAI_API_KEY
      api_version: os.environ/AZURE_OPENAI_API_VERSION
      rpm: 60
      tpm: 80000

  # OpenAI deployment for gpt-4.1 (same model_name = auto load balance)
  - model_name: gpt-4.1
    litellm_params:
      model: openai/gpt-4.1
      api_key: os.environ/OPENAI_API_KEY
      rpm: 500
      tpm: 150000

router_settings:
  routing_strategy: simple-shuffle
  redis_host: litellm-redis
  redis_port: 6379
  num_retries: 3
  timeout: 600
  # Failover settings: mark deployment unhealthy after 1 failure, cooldown for 60s
  allowed_fails: 1
  cooldown_time: 60
  # Retry on different deployment when rate limited
  retry_after: 0

litellm_settings:
  drop_params: true
  set_verbose: false
  cache: true
  cache_params:
    type: redis
    host: litellm-redis
    port: 6379
    default_in_redis_ttl: 3600
    supported_call_types: ["atext_completion", "aembedding", "atranscription"]
  success_callback: ["arize_phoenix"]

general_settings:
  master_key: os.environ/LITELLM_MASTER_KEY
  database_url: os.environ/LITELLM_DATABASE_URL
  store_model_in_db: true
  store_prompts_in_spend_logs: true
